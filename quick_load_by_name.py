"""
æŒ‰åç§°åŠ è½½èŠ‚ç‚¹ - æ— éœ€è¾“å…¥è·¯å¾„ï¼Œç›´æ¥é€‰æ‹©èŠ‚ç‚¹åŒ…åç§°
"""

from pathlib import Path
import json
from typing import Tuple, List, Dict, Any, Optional
from .workflow_generator import WorkflowGenerator


class QuickLoadByName:
    """
    æŒ‰åç§°åŠ è½½èŠ‚ç‚¹
    
    åŠŸèƒ½ï¼š
    - è‡ªåŠ¨æ‰«æ custom_nodes ç›®å½•
    - ä¸‹æ‹‰èœå•é€‰æ‹©èŠ‚ç‚¹åŒ…
    - æ— éœ€æ‰‹åŠ¨è¾“å…¥è·¯å¾„
    - ä¸€é”®ç”Ÿæˆå·¥ä½œæµ
    """
    
    @classmethod
    def get_custom_nodes_list(cls) -> List[str]:
        """è·å–æ‰€æœ‰å·²å®‰è£…çš„è‡ªå®šä¹‰èŠ‚ç‚¹åŒ…åˆ—è¡¨"""
        try:
            # è·å– custom_nodes ç›®å½•
            current_file = Path(__file__)
            custom_nodes_dir = current_file.parent.parent
            
            if not custom_nodes_dir.exists():
                return ["(æœªæ‰¾åˆ°èŠ‚ç‚¹åŒ…)"]
            
            # æ‰«ææ‰€æœ‰å­ç›®å½•
            node_packages = []
            for item in custom_nodes_dir.iterdir():
                if item.is_dir() and not item.name.startswith('.'):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„èŠ‚ç‚¹åŒ…ï¼ˆåŒ…å« __init__.py æˆ– Python æ–‡ä»¶ï¼‰
                    has_init = (item / "__init__.py").exists()
                    has_py = any(item.glob("*.py"))
                    
                    if has_init or has_py:
                        node_packages.append(item.name)
            
            # æ’åºå¹¶è¿”å›
            node_packages.sort()
            
            if not node_packages:
                return ["(æœªæ‰¾åˆ°èŠ‚ç‚¹åŒ…)"]
            
            return node_packages
            
        except Exception as e:
            print(f"[ERROR] è·å–èŠ‚ç‚¹åŒ…åˆ—è¡¨å¤±è´¥: {e}")
            return ["(æ‰«æå¤±è´¥)"]
    
    @classmethod
    def INPUT_TYPES(cls):
        node_packages = ["æ— ", "å…¨éƒ¨"] + cls.get_custom_nodes_list()
        presets = cls.load_cleanup_presets()
        preset_names = ["æ— "] + sorted(presets.keys())
        
        return {
            "required": {
                "èŠ‚ç‚¹åŒ…åç§°": (node_packages, {
                    "default": node_packages[0] if node_packages else "æ— "
                }),
                "å¸ƒå±€æ¨¡å¼": (["æ™ºèƒ½å¸ƒå±€", "ç´§å‡‘å¸ƒå±€", "å®½æ¾å¸ƒå±€"], {
                    "default": "æ™ºèƒ½å¸ƒå±€"
                }),
                "åˆ·æ–°èŠ‚ç‚¹åˆ—è¡¨": ("BOOLEAN", {
                    "default": False
                }),
            },
            "optional": {
                "åˆ†ç±»ç­›é€‰": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "åˆ é™¤é¢„è®¾": (preset_names, {
                    "default": preset_names[1] if len(preset_names) > 1 else "æ— "
                }),
                "åˆ é™¤å‰ç¼€": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥æ–‡ä»¶åå‰ç¼€ä»¥åˆ é™¤æ—§å·¥ä½œæµ"
                }),
                "åˆ é™¤å…³é”®å­—": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥å…³é”®å­—ä»¥åˆ é™¤æ—§å·¥ä½œæµ"
                }),
                "æ·»åŠ é¢„è®¾": ("BOOLEAN", {
                    "default": False
                }),
                "æ–°é¢„è®¾åç§°": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "æ–°é¢„è®¾å‰ç¼€": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "æ–°é¢„è®¾å…³é”®å­—": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "åˆ é™¤é¢„è®¾åç§°": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "INT")
    RETURN_NAMES = ("å·¥ä½œæµJSON", "JSONè·¯å¾„", "æ“ä½œè¯´æ˜", "èŠ‚ç‚¹æ•°é‡")
    FUNCTION = "quick_load_by_name"
    CATEGORY = "haigc_toolkit/utils"
    OUTPUT_NODE = True
    
    def quick_load_by_name(self, **inputs: Any) -> Tuple[str, str, str, int]:
        """
        æŒ‰åç§°åŠ è½½èŠ‚ç‚¹
        
        Returns:
            (å·¥ä½œæµJSON, JSONè·¯å¾„, ä½¿ç”¨è¯´æ˜, èŠ‚ç‚¹æ•°é‡)
        """
        try:
            # è¯»å–ä¸­è‹±æ–‡å‚æ•°ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            node_package = inputs.get("èŠ‚ç‚¹åŒ…åç§°") or inputs.get("node_package") or ""
            mode = inputs.get("å¸ƒå±€æ¨¡å¼") or inputs.get("mode") or "æ™ºèƒ½å¸ƒå±€"
            refresh_list = inputs.get("åˆ·æ–°èŠ‚ç‚¹åˆ—è¡¨")
            if refresh_list is None:
                refresh_list = inputs.get("refresh_list", False)
            filter_category = inputs.get("åˆ†ç±»ç­›é€‰") or inputs.get("filter_category") or ""
            preset_name = inputs.get("åˆ é™¤é¢„è®¾") or inputs.get("cleanup_preset") or "æ— "
            add_preset = inputs.get("æ·»åŠ é¢„è®¾") or inputs.get("add_preset", False)
            new_preset_name = inputs.get("æ–°é¢„è®¾åç§°") or inputs.get("new_preset_name", "")
            new_preset_prefix = inputs.get("æ–°é¢„è®¾å‰ç¼€") or inputs.get("new_preset_prefix", "")
            new_preset_keyword = inputs.get("æ–°é¢„è®¾å…³é”®å­—") or inputs.get("new_preset_keyword", "")
            remove_preset_name = inputs.get("åˆ é™¤é¢„è®¾åç§°") or inputs.get("remove_preset_name", "")
            cleanup_prefix = inputs.get("åˆ é™¤å‰ç¼€") or inputs.get("cleanup_prefix") or ""
            cleanup_keyword = inputs.get("åˆ é™¤å…³é”®å­—") or inputs.get("cleanup_keyword") or ""
            
            presets = self.load_cleanup_presets()
            
            if add_preset and new_preset_name.strip():
                presets[new_preset_name.strip()] = {
                    "prefix": new_preset_prefix.strip(),
                    "keyword": new_preset_keyword.strip()
                }
                self.save_cleanup_presets(presets)
                print(f"[é¢„è®¾] å·²æ–°å¢/æ›´æ–°é¢„è®¾: {new_preset_name.strip()}")
                preset_name = new_preset_name.strip()
            
            if remove_preset_name.strip():
                if remove_preset_name.strip() in presets:
                    presets.pop(remove_preset_name.strip())
                    self.save_cleanup_presets(presets)
                    print(f"[é¢„è®¾] å·²åˆ é™¤é¢„è®¾: {remove_preset_name.strip()}")
                    if preset_name == remove_preset_name.strip():
                        preset_name = "æ— "
            
            if preset_name != "æ— ":
                preset_data = presets.get(preset_name, {})
                if preset_data:
                    if not cleanup_prefix:
                        cleanup_prefix = preset_data.get("prefix", "")
                    if not cleanup_keyword:
                        cleanup_keyword = preset_data.get("keyword", "")
            
            print("\n" + "="*70)
            print("[æŒ‰åç§°åŠ è½½] å¿«é€ŸåŠ è½½æ¨¡å¼".center(70))
            print("="*70)
            
            # éªŒè¯é€‰æ‹©
            if node_package in ["(æœªæ‰¾åˆ°èŠ‚ç‚¹åŒ…)", "(æ‰«æå¤±è´¥)"]:
                error = "[é”™è¯¯] è¯·é€‰æ‹©æœ‰æ•ˆçš„èŠ‚ç‚¹åŒ…"
                return ("", "", error, 0)
            
            cleanup_prefix = cleanup_prefix.strip()
            cleanup_keyword = cleanup_keyword.strip()
            
            # ä½¿ç”¨å·¥ä½œæµç”Ÿæˆå™¨
            generator = WorkflowGenerator()
            
            deleted_files: List[str] = []
            if cleanup_prefix or cleanup_keyword:
                print("\n[æ¸…ç†] æ­£åœ¨åˆ é™¤æ—§å·¥ä½œæµæ–‡ä»¶...")
                deleted_files = generator.delete_workflows(
                    prefix=cleanup_prefix,
                    keyword=cleanup_keyword
                )
                print(f"[æ¸…ç†] åˆ é™¤åŒ¹é…æ–‡ä»¶ {len(deleted_files)} ä¸ª")
            
            # è·å–å¸ƒå±€é…ç½®
            layout_config = self._get_layout_config(mode)
            layout_label = layout_config.get("label", mode)
            
            # æ ¹æ®é€‰æ‹©å¤„ç†ä¸åŒæƒ…å†µ
            generated_results: List[Tuple[str, int, str]] = []
            
            if node_package == "æ— ":
                print("\n[æç¤º] æœªé€‰æ‹©èŠ‚ç‚¹åŒ…ï¼Œä»…æ‰§è¡Œæ¸…ç†æ“ä½œã€‚")
            elif node_package == "å…¨éƒ¨":
                # æ‰¹é‡å¤„ç†æ‰€æœ‰èŠ‚ç‚¹åŒ…
                all_packages = self.get_custom_nodes_list()
                print(f"\n[ç›®æ ‡] æ‰¹é‡å¤„ç† {len(all_packages)} ä¸ªèŠ‚ç‚¹åŒ…")
                
                print(f"\n[å¸ƒå±€] æ¨¡å¼: {layout_label}")
                print(f"   - ç±»å‹: {layout_config['type']}")
                print(f"   - é—´è·: {layout_config['spacing_x']}x{layout_config['spacing_y']}px")
                
                for pkg in all_packages:
                    pkg_path = self._get_package_path(pkg)
                    if not pkg_path or not pkg_path.exists():
                        print(f"[è­¦å‘Š] èŠ‚ç‚¹åŒ…è·¯å¾„æ— æ•ˆï¼Œè·³è¿‡: {pkg}")
                        continue
                    
                    print(f"\n[ç›®æ ‡] èŠ‚ç‚¹åŒ…: {pkg}")
                    print(f"[è·¯å¾„] {pkg_path}")
                    if filter_category:
                        print(f"[ç­›é€‰] åˆ†ç±»: {filter_category}")
                    
                    print("\n[æ‰«æ] æ­£åœ¨æ‰«æèŠ‚ç‚¹...")
                    
                    try:
                        result = generator.generate_workflow(
                            package_path=str(pkg_path),
                            layout_type=layout_config['type'],
                            spacing_x=layout_config['spacing_x'],
                            spacing_y=layout_config['spacing_y'],
                            save_to_file=True,
                            output_path="",
                            filter_category=filter_category,
                            seed=None
                        )
                        
                        workflow_json, node_count, json_path = result
                        
                        if node_count == 0:
                            print(f"[è­¦å‘Š] æœªæ‰¾åˆ°èŠ‚ç‚¹ï¼Œè·³è¿‡: {pkg}")
                            continue
                        
                        print(f"\n[æˆåŠŸ] ç”Ÿæˆå·¥ä½œæµå®Œæˆï¼")
                        print(f"   - èŠ‚ç‚¹æ•°é‡: {node_count}")
                        print(f"   - JSON: {json_path}")
                        
                        generated_results.append((workflow_json, node_count, json_path))
                    except Exception as e:
                        print(f"[é”™è¯¯] å¤„ç†èŠ‚ç‚¹åŒ…å¤±è´¥ {pkg}: {e}")
                        continue
            else:
                # å•ä¸ªèŠ‚ç‚¹åŒ…
                package_path = self._get_package_path(node_package)
                if not package_path or not package_path.exists():
                    error = f"[é”™è¯¯] èŠ‚ç‚¹åŒ…è·¯å¾„æ— æ•ˆ: {node_package}"
                    print(f"\n{error}")
                    return ("", "", error, 0)
                
                print(f"\n[ç›®æ ‡] èŠ‚ç‚¹åŒ…: {node_package}")
                print(f"[è·¯å¾„] {package_path}")
                if filter_category:
                    print(f"[ç­›é€‰] åˆ†ç±»: {filter_category}")
                
                print(f"\n[å¸ƒå±€] æ¨¡å¼: {layout_label}")
                print(f"   - ç±»å‹: {layout_config['type']}")
                print(f"   - é—´è·: {layout_config['spacing_x']}x{layout_config['spacing_y']}px")
                
                print("\n[æ‰«æ] æ­£åœ¨æ‰«æèŠ‚ç‚¹...")
                
                result = generator.generate_workflow(
                    package_path=str(package_path),
                    layout_type=layout_config['type'],
                    spacing_x=layout_config['spacing_x'],
                    spacing_y=layout_config['spacing_y'],
                    save_to_file=True,
                    output_path="",
                    filter_category=filter_category,
                    seed=None
                )
                
                workflow_json, node_count, json_path = result
                
                if node_count == 0:
                    error = "[é”™è¯¯] æœªæ‰¾åˆ°ä»»ä½•èŠ‚ç‚¹"
                    print(f"\n{error}")
                    return ("", "", error, 0)
                
                print(f"\n[æˆåŠŸ] ç”Ÿæˆå·¥ä½œæµå®Œæˆï¼")
                print(f"   - èŠ‚ç‚¹æ•°é‡: {node_count}")
                print(f"   - JSON: {json_path}")
                
                generated_results.append((workflow_json, node_count, json_path))
            
            # å¤„ç†è¾“å‡º
            if generated_results:
                if node_package == "å…¨éƒ¨":
                    # è¿”å›æ‰¹é‡ç”Ÿæˆçš„æ±‡æ€»ä¿¡æ¯
                    total_nodes = sum(res[1] for res in generated_results)
                    json_paths_list = [res[2] for res in generated_results]
                    workflow_json = ""  # æ‰¹é‡æ¨¡å¼ä¸è¿”å›å•ä¸ªå·¥ä½œæµJSON
                    json_path = "\n".join(json_paths_list)
                else:
                    # è¿”å›å•ä¸ªèŠ‚ç‚¹åŒ…çš„ç»“æœ
                    workflow_json, node_count, json_path = generated_results[0]
                    total_nodes = node_count
                
                instructions = self._generate_instructions(
                    json_path=json_path,
                    package_name=node_package,
                    node_count=total_nodes,
                    deleted_files=deleted_files,
                    cleanup_prefix=cleanup_prefix,
                    cleanup_keyword=cleanup_keyword,
                    preset_name=preset_name,
                    generated=True,
                    batch_results=generated_results if node_package == "å…¨éƒ¨" else None
                )
                
                return (workflow_json, json_path, instructions, total_nodes)
            else:
                # æ²¡æœ‰ç”Ÿæˆä»»ä½•å·¥ä½œæµï¼ˆå¯èƒ½æ˜¯é€‰æ‹©äº†"æ— "æˆ–å…¨éƒ¨å¤±è´¥ï¼‰
                instructions = self._generate_instructions(
                    json_path="",
                    package_name=node_package,
                    node_count=0,
                    deleted_files=deleted_files,
                    cleanup_prefix=cleanup_prefix,
                    cleanup_keyword=cleanup_keyword,
                    preset_name=preset_name,
                    generated=False,
                    batch_results=None
                )
                
                return ("", "", instructions, 0)
            
        except Exception as e:
            error_msg = f"[é”™è¯¯] åŠ è½½å¤±è´¥: {str(e)}"
            print(f"\n{error_msg}")
            import traceback
            traceback.print_exc()
            return ("", "", error_msg, 0)
    
    def _get_package_path(self, package_name: str) -> Path:
        """æ ¹æ®åŒ…åè·å–å®Œæ•´è·¯å¾„"""
        try:
            current_file = Path(__file__)
            custom_nodes_dir = current_file.parent.parent
            package_path = custom_nodes_dir / package_name
            return package_path
        except Exception as e:
            print(f"[ERROR] è·å–è·¯å¾„å¤±è´¥: {e}")
            return None
    
    def _get_layout_config(self, mode: str) -> Dict[str, Any]:
        """è·å–å¸ƒå±€é…ç½®"""
        mode_key = {
            "æ™ºèƒ½å¸ƒå±€": "smart",
            "ç´§å‡‘å¸ƒå±€": "compact",
            "å®½æ¾å¸ƒå±€": "spacious"
        }.get(mode, "smart")
        
        configs = {
            "smart": {
                "type": "grid",
                "spacing_x": 450,
                "spacing_y": 300,
                "description": "æ™ºèƒ½ç½‘æ ¼å¸ƒå±€ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ",
                "label": "æ™ºèƒ½å¸ƒå±€"
            },
            "compact": {
                "type": "compact",
                "spacing_x": 350,
                "spacing_y": 220,
                "description": "ç´§å‡‘å¸ƒå±€ï¼ŒèŠ‚çœç©ºé—´",
                "label": "ç´§å‡‘å¸ƒå±€"
            },
            "spacious": {
                "type": "grid",
                "spacing_x": 550,
                "spacing_y": 350,
                "description": "å®½æ¾å¸ƒå±€ï¼ŒèŠ‚ç‚¹é—´è·å¤§",
                "label": "å®½æ¾å¸ƒå±€"
            }
        }
        return configs.get(mode_key, configs["smart"])
    
    def _generate_instructions(
        self,
        json_path: str,
        package_name: str,
        node_count: int,
        deleted_files: Optional[List[str]],
        cleanup_prefix: str,
        cleanup_keyword: str,
        preset_name: str,
        generated: bool,
        batch_results: Optional[List[Tuple[str, int, str]]] = None
    ) -> str:
        """ç”Ÿæˆä½¿ç”¨è¯´æ˜"""
        deleted_files = deleted_files or []
        
        lines = [
            f"[åŒ…å] {package_name}",
            f"[èŠ‚ç‚¹] {node_count} ä¸ª",
        ]
        if preset_name and preset_name != "æ— ":
            lines.append(f"[é¢„è®¾] {preset_name}")
        
        if cleanup_prefix or cleanup_keyword:
            lines.append("")
            lines.append("[æ¸…ç†]")
            condition = []
            if cleanup_prefix:
                condition.append(f"å‰ç¼€='{cleanup_prefix}'")
            if cleanup_keyword:
                condition.append(f"åŒ…å«='{cleanup_keyword}'")
            lines.append("æ¡ä»¶: " + " ä¸” ".join(condition))
            lines.append(f"åˆ é™¤ {len(deleted_files)} ä¸ªåŒ¹é…æ–‡ä»¶")
            preview = deleted_files[:5]
            for path in preview:
                lines.append(f"  - {Path(path).name}")
            if len(deleted_files) > len(preview):
                lines.append("  ...")
        
        if generated:
            if batch_results and len(batch_results) > 0:
                # æ‰¹é‡ç”Ÿæˆæ¨¡å¼
                lines.extend([
                    "",
                    "[æ‰¹é‡ç”Ÿæˆ]",
                    f"æˆåŠŸç”Ÿæˆ {len(batch_results)} ä¸ªå·¥ä½œæµæ–‡ä»¶"
                ])
                for idx, (_, count, path) in enumerate(batch_results, 1):
                    pkg_name = Path(path).stem.replace("workflow_", "").replace("_all_nodes", "")
                    lines.append(f"{idx}. {pkg_name}: {count} ä¸ªèŠ‚ç‚¹")
                    lines.append(f"   {path}")
                
                lines.extend([
                    "",
                    "[å¯¼å…¥æ–¹æ³•]",
                    "æ–¹æ³• 1: ä½¿ç”¨ JSON æ–‡ä»¶",
                    "  1. ç‚¹å‡»å³ä¸Šè§’çš„ 'Load' æŒ‰é’®",
                    "  2. é€‰æ‹©ä¸Šé¢åˆ—å‡ºçš„ä»»æ„ JSON æ–‡ä»¶",
                    "",
                    "æ–¹æ³• 2: æ‰¹é‡å¯¼å…¥",
                    "  - å¯ä»¥ä¾æ¬¡åŠ è½½å¤šä¸ªå·¥ä½œæµæ–‡ä»¶",
                    "  - æ¯ä¸ªæ–‡ä»¶åŒ…å«å¯¹åº”èŠ‚ç‚¹åŒ…çš„æ‰€æœ‰èŠ‚ç‚¹"
                ])
            elif json_path:
                # å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼
                lines.extend([
                    "",
                    "[æ–‡ä»¶ä½ç½®]",
                    "workflow_json: ï¼ˆèŠ‚ç‚¹è¾“å‡ºï¼Œå¯ç»§ç»­ä¼ é€’ï¼‰",
                    f"JSON: {json_path}",
                    "",
                    "[å¯¼å…¥æ–¹æ³•]",
                    "æ–¹æ³• 1: ä½¿ç”¨ JSON æ–‡ä»¶",
                    "  1. ç‚¹å‡»å³ä¸Šè§’çš„ 'Load' æŒ‰é’®",
                    "  2. é€‰æ‹©ä¸Šé¢çš„ JSON æ–‡ä»¶",
                    "",
                    "æ–¹æ³• 2: ä½¿ç”¨ workflow_json è¾“å‡º",
                    "  - å°† workflow_json è¿æ¥åˆ°ä¿å­˜èŠ‚ç‚¹ï¼ˆJSONï¼‰",
                    "  - æˆ–ä¼ é€’ç»™è‡ªå®šä¹‰å¤„ç†èŠ‚ç‚¹"
                ])
        else:
            lines.extend([
                "",
                "[æ–‡ä»¶ä½ç½®]",
                "æœ¬æ¬¡æœªç”Ÿæˆæ–°å·¥ä½œæµï¼ˆä»…æ‰§è¡Œæ¸…ç†ï¼‰"
            ])
        
        return "\n".join(lines)

    @staticmethod
    def load_cleanup_presets() -> Dict[str, Dict[str, str]]:
        """åŠ è½½åˆ é™¤é¢„è®¾ï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤é¢„è®¾"""
        preset_path = Path(__file__).parent / "cleanup_presets.json"
        if not preset_path.exists():
            presets = {"workflow": {"prefix": "workflow", "keyword": ""}}
            preset_path.write_text(json.dumps(presets, ensure_ascii=False, indent=2), encoding="utf-8")
            return presets
        try:
            data = json.loads(preset_path.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                return data
            raise ValueError("é¢„è®¾æ–‡ä»¶æ ¼å¼æ— æ•ˆ")
        except Exception as exc:
            print(f"[è­¦å‘Š] è¯»å–é¢„è®¾å¤±è´¥: {exc}ï¼Œä½¿ç”¨é»˜è®¤é¢„è®¾")
            return {"workflow": {"prefix": "workflow", "keyword": ""}}

    @staticmethod
    def save_cleanup_presets(presets: Dict[str, Dict[str, str]]) -> None:
        """ä¿å­˜åˆ é™¤é¢„è®¾"""
        preset_path = Path(__file__).parent / "cleanup_presets.json"
        preset_path.write_text(json.dumps(presets, ensure_ascii=False, indent=2), encoding="utf-8")


NODE_CLASS_MAPPINGS = {
    "QuickLoadByName": QuickLoadByName,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "QuickLoadByName": "æŒ‰åç§°åŠ è½½èŠ‚ç‚¹ ğŸ“",
}

